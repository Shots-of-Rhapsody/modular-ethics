# Ethics Testbed â€” Modular Moral Reasoning

![Build](https://img.shields.io/github/actions/workflow/status/Shots-of-Rhapsody/modular-ethics/ci.yml?branch=main)  
![Coverage](https://img.shields.io/codecov/c/github/Shots-of-Rhapsody/modular-ethics/main)  
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)  
![Version](https://img.shields.io/github/v/release/Shots-of-Rhapsody/modular-ethics)  
![Last Commit](https://img.shields.io/github/last-commit/Shots-of-Rhapsody/modular-ethics/main)  
![Contributors](https://img.shields.io/github/contributors/Shots-of-Rhapsody/modular-ethics)  
![Open Issues](https://img.shields.io/github/issues/Shots-of-Rhapsody/modular-ethics)  
![PRs](https://img.shields.io/github/issues-pr/Shots-of-Rhapsody/modular-ethics)  

**Ethics Testbed** is an experimental framework that translates ethical theories into **composable mathematical programs**.  
It is designed to make moral reasoning **transparent, auditable, and comparable** across different traditions of thought.  

The project is in active development & welcomes contributors who are interested in philosophy, mathematics, cognitive science, or applied AI ethics.

---

## ğŸ” Purpose

Ethical debates often get stuck in rhetoric. This project aims to:

- **Formalize**: Represent normative theories (consequentialism, deontology, virtue ethics & others) in math-like evaluators.  
- **Separate**: Distinguish *facts* (causal models, probabilities) from *values* (weights, duties, virtues).  
- **Aggregate**: Handle pluralism by explicitly modeling moral uncertainty & combining multiple evaluators.  
- **Constrain**: Encode rights & duties as side-constraints, ensuring no rule-breaking is hidden in the math.  
- **Audit**: Generate explanation sets that highlight *which premises did the real work* in each recommendation.  

---

## ğŸ“‚ Repository Structure

â”œâ”€â”€ public/ â† static front-end assets (HTML, CSS, JS)
â”œâ”€â”€ src/ â† source code (interactive logic, UI, engine)
â”œâ”€â”€ data/
â”‚ â””â”€â”€ scenarios.json â† seed moral dilemmas and case definitions
â”œâ”€â”€ assets/ â† site-wide styles, shared scripts
â”œâ”€â”€ scripts/ â† build / deployment or utility scripts
â”œâ”€â”€ ROADMAP.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ LICENSE.md
â”œâ”€â”€ package.json / lock
â””â”€â”€ lychee.toml â† static-site / link-checker config


Key pages and modules:

- `index.html` â€” Home / project overview  
- `paper.html` â€” Expository / methods document  
- `language-math.html` â€” On the correspondence between language and formal rules  
- `research.html` â€” Explorations of math, philosophy, and world structure  
- `results.html` â€” Interactive dashboard: compare evaluator outputs  
- `interactive.html` â€” Slider & constraint interface for sensitivity analysis  
- `js/engine.js` â€” Core engine: module definitions, aggregation logic, explanation derivation  
- `data/scenarios.json` â€” Scenario definitions and metadata  

---

## ğŸ§© Current Features

- Formal mathematical definitions of **Consequentialism, Deontology, & Virtue Ethics**  
- **Scenario schema (JSON)** for portable ethical case studies  
- Interactive **results viewer** with sliders to adjust credences & trait weights  
- **Normalization pipeline** to make modules comparable under aggregation  
- Clear UI/UX emphasis on **transparency and accessibility**  

---

## ğŸš§ In Progress

- Expanding scenario library (policy, global health, AI decision-making)  
- Adding new modules: Rawlsian max-min fairness, contractualism, care ethics  
- Enhanced visualization: heatmaps, causal graphs & interactive explanations  
- Integration with external datasets (e.g., real-world triage protocols, public health stats)  
- Peer-reviewed research paper aligning the engine with cognitive science & mathematical theology  

---

## ğŸ”® Future Directions

- Build a **scenario editor** so new dilemmas can be authored via the browser  
- Incorporate **probabilistic causal models** to test robustness of recommendations  
- Explore cross-disciplinary applications: legal reasoning, AI alignment & global policy  
- Develop a lightweight **API layer** for integration with other ethical/AI tools  
- Community-driven **axiom ledger** for iterative refinement of normative assumptions  

---

## ğŸ“– Contributing

We welcome all kinds of contributions: philosophy, modeling, UI/visual design, code, testing, documentation.  
See [`contribute.html`](contribute.html) or open an [issue](https://github.com/Shots-of-Rhapsody/modular-ethics/issues).  

Ways to help:  
- Add or refine scenarios in `data/scenarios.json`  
- Extend or propose new modules in `js/engine.js`  
- Improve UI usability, mobile support, accessibility  
- Suggest or test axioms, alternative aggregation schemes, explanation methods  
- Report bugs, open issues, propose features  
- See [CONTRIBUTING](./CONTRIBUTING.md) for full guidelines  

---

## ğŸ“œ License

This project is released under the **MIT License**.  
You are free to use, modify & distribute with attribution.  

---

## âœ¨ Acknowledgments

- Inspired by **Eugene Wignerâ€™s** question of mathâ€™s â€œunreasonable effectiveness.â€  
- Informed by traditions across **philosophy, cognitive science, and AI ethics**.  
- Designed so moral reasoning is treated as a research subject â€” **auditable & reproducible** as scientific experiments.  

---

## ğŸŒ About

- **Modular Ethics Project**  
- Website: [shotsofrhapsody.com](https://shotsofrhapsody.com)  

**Resources**  
- Project homepage / live demo  
- ROADMAP & development notes  
- Security policy & code of conduct  

---

*Last updated: <!--AUTO-DATE-->*